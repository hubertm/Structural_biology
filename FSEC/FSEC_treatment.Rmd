---
title: "Integration of FSEC peaks using R"
output: html_document
---

This tutorial explains how to use R to analyse FSEC / tFSEC curves. The same analysis can be done manually using Chromelab - and depending on the number this could even be shorter! Also, *looking* at the shapes of the chromatograms is an obvious advantage of manual treatment over scripted treatment. Still using scripts and a programmation language will have some interest for repetitive experiments when peaks are well-defined.

## Foreplays: export data and cleansing of the header

On the machineâ€™s computer, open simultaneously the runs in Chromelab. *Do not* play with the visible curves and export in cvs format. If you process a lot of runs you're likely to obtain a huge file. Here the file cointaining the 32 runs weight about 50 Mo. Alternatively, you can choose to untick all curves but the fluo ones (that means 96 unticking+scrolling in this case... awful, but can be quick if you work with just a few runs).

Most of the data we are not interested in, and the first thing to do is to throw away all curves (A280, Conductivity, %B) but the fluo ones. To do this you need to keep only the 7th,8th,15th,16th,23th,24th,etc... columns in your data. The (8n-1)th columns contain volumes, the (8n)th columns contains fluorescence values.

This is done with **in a shell terminal** with the command
Shell script (Bash) to prepare the file for the R script
'''
#!/bin/sh

a=1
time=0
intensity=0
string=""
while [ $a -lt 17 ]
do
   time=$((8*${a}-1))
   intensity=$((8*${a}))
   string+=$time","$intensity","
   a=`expr $a + 1`
done
echo "Cutting ...."
cut -d ',' -f ${string%?} "$1" > trimmed.csv
echo "Removing commas ...."
grep -v ",," trimmed.csv>cleaned.csv
echo "Removing the 2nd line ...."
sed '2d' cleaned.csv>${1%????}Ready.csv
rm cleaned.csv
rm trimmed.csv
'''

###In BASH to preserve the labels of the runs:  
####Under Linux at least it works. Mac OS X uses a different flavour of sed and has a different syntax):
~~~~~~~~~~
sed -n 1p toto.csv>line1
for i in {1..20}
do
cut -d ',' -f $((i*2)) line1 >>tmp.csv
echo $i >>tmp.csv
done
sed -i 's/\s//g' tmp.csv 
rm line1
#remove the newlines
sed ':a;N;$!ba;s/\n/,/g' tmp1.csv > processed.csv
rm tmp*

sed -i -e 1,2d toto.csv
#-i replaces the original file -e adds the script to the commands to be executed
#The command removes the first 2 lines

sed -e :a -e '$d;N;2,5ba' -e 'P;D' toto.csv > tmpfile ; mv tmpfile toto.csv
#Removes the last 5 lines
cat toto.csv>>processed.csv
rm toto.csv
#To check the number of the lines (Bash)
------
wc -l toto.cvs 
~~~~~~~~~~

## Import of the data and data structure

Now you can read in R the .csv file

```{r}
fluo=read.csv("toto.csv")
```

The variable fluo is a kind of table. It contains `2n` sub-variables that are the volumes and fluorescence values for each run. In R studio you can see the structure of the variable on the top right panel. In the console, you can access to one subvariable using its column number starting from 1, e.g. 5 is the volume for run 3, 6 is the fluo for run 3.

## Peak integration and baseline substraction

As we need a function to calculate the area under the curve that is not installed by default in R, let's load the library MESS that contains the function `auc` (Area Under Curve). If you're never used this library it first needs to be installed with the function

#```{r,eval=FALSE}
#install.packages("MESS")
#```

```{r}
library("MESS")
```

The syntax of this function is ultra-simple, you provide a set of points for x and y, and eventually border in x for the integration

```{r}
auc(fluo[,1],fluo[,2])
auc(fluo[,1],fluo[,2],12,13)
```

One caveat is that the curves do not have a zero baseline, therefore the result of the peak integration is not correct (I get 557). We can substract the mean of the first milliliters of the run (here the first 5 mL), that should be a good approximate of the baseline. Let's do that for the first run and store the result in a new object called *fluo_baseline*

```{r}
fluo_baseline <- fluo[,2] - mean(fluo[,2][fluo[,1]<5])
```

Now the auc function should give the proper results

```{r}
auc(fluo[,1],fluo_baseline,12,13)
```

The baseline substraction need to be applied to all runs in the dataset. We can use a *for* loop to do that, replacing each fluorescence data by its value minus the baseline. The fluorescence data are in the even columns, so let's modify only the columns *2n* when *n* varies from 1 to half of the number of runs.

```{r}
for (n in 1:(length(fluo)/2) )
  {
  fluo[2*n] <- fluo[2*n] - mean(fluo[2*n][fluo[2*n-1]<5])
  }
```

*Note* This piece of code works only if there are no missing values by zeros, hence the foreplay section.

Now if you replot the curve for the first sample, you can see the baseline has gone from about 100 to about 0

```{r, echo=TRUE}
for (n in 1:(length(fluo)/2) )
  {
  plot(fluo[,2*n-1],fluo[,2*n],type="l",col="green", main = names(fluo[n*2-1]), xlab = "ml", ylab = "mV")
  }
```
#The comma in the plot before the index of what is to be plotted is need (plot(fluo[,2*n-1]) as fluo is a data.frame but plot wants a vector. One can also transpose it to plot things.
## Construction of the comparison plot for all runs

Let's create a new vector of *n* values (the number of runs) containing the integrated values for each run. This is done once again with a *for* loop.

```{r}
peak = NULL
for (n in 1:(length(fluo)/2) )
{
  peak[n] <- auc(fluo[,2*n-1],fluo[,2*n],12,13)
}
```

*Note* Before being used in a loop, variable needs to exist, hence the *peak = NULL* line.

Ok, we're done, the histogram of the values under the curve for all runs can now be drawn

```{r}
barplot(peak)
```

Just for comparison, we can use the peak height instead of the area under the curve

```{r}
height = NULL
for (n in 1:(length(fluo)/2) )
{
  height[n] <- max(fluo[,2*n][fluo[,2*n-1]>12 & fluo[,2*n-1]<13])
}
barplot(height)
```
ADDITION
read.csv reads the data as character. This will transform it into the type double
```{r}
test<-data.matrix(fluo[1:2])
```

